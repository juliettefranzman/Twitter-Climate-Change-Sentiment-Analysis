{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import naive_bayes, logistic, random_forest\n",
    "from models import naive_bayes, logistic, random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "data = pd.read_csv('clean_data.csv.txt',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only tweets that are pro and anti\n",
    "binary_data = data[data[\"sentiment\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into testing and training sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(binary_data.drop(labels = \"sentiment\", axis = 1), binary_data[\"sentiment\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select just the numerical data\n",
    "X_train_numerical = X_train.loc[:, ['is_retweet', 'is_quoted', 'retweets', 'favorites', 'followers', 'verified',\n",
    "               'exclamation_mark_count', 'question_mark_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Perform 5-fold cross validation on each of the potential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the models and obtain test error estimates\n",
    "nb = naive_bayes(X_train[\"clean text\"].values, y_train.values)\n",
    "log = logistic(X_train[\"clean text\"].values, y_train.values)\n",
    "rf = random_forest(X_train[\"clean text\"].values, y_train.values)\n",
    "log_with_numeric = logistic(X_train[\"clean text\"].values, y_train.values, X_train_numerical.values)\n",
    "rf_with_numeric = random_forest(X_train[\"clean text\"].values, y_train.values, X_train_numerical.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.879396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.884261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression with Numerical</td>\n",
       "      <td>0.841711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest with Numerical</td>\n",
       "      <td>0.873637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy\n",
       "0                         Naive Bayes  0.879396\n",
       "1                 Logistic Regression  0.884261\n",
       "2                       Random Forest  0.873637\n",
       "3  Logistic Regression with Numerical  0.841711\n",
       "4        Random Forest with Numerical  0.873637"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df = pd.DataFrame(data ={'Model':['Naive Bayes',\n",
    "                            'Logistic Regression',\n",
    "                            'Random Forest', \n",
    "                             'Logistic Regression with Numerical',\n",
    "                            'Random Forest with Numerical'], 'Accuracy': [nb,log,rf,log_with_numeric,rf_with_numeric] } )\n",
    "binary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression had the best accuracy rate. This will be our final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the best model and obtain the final test error estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8761180679785331"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "train = vectorizer.fit_transform(X_train[\"clean text\"].values)\n",
    "test = vectorizer.transform(X_test[\"clean text\"].values)\n",
    "        \n",
    "#run logistic regression\n",
    "logistic_classifier = LogisticRegression(random_state=0, max_iter = 2000)\n",
    "logistic_classifier.fit(train, y_train.values)\n",
    "        \n",
    "#obtain the test accuracy\n",
    "logistic_classifier.score(test, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vec = vectorizer.fit_transform(data[\"clean text\"].values)\n",
    "        \n",
    "#run logistic regression\n",
    "logistic_classifier = LogisticRegression(random_state=0, max_iter = 2000)\n",
    "logistic_classifier.fit(vec, data[\"sentiment\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.064229  , -0.08045319, -0.01437724, ..., -0.00890921,\n",
       "         0.67050556,  0.39071954],\n",
       "       [ 0.39435001, -0.45111389, -0.08785605, ...,  0.33158911,\n",
       "        -0.13981684, -0.27403148],\n",
       "       [-0.33012102,  0.53156708,  0.10223329, ..., -0.32267991,\n",
       "        -0.53068872, -0.11668806]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a 3 Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(labels = \"sentiment\", axis = 1), data[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select just the numerical data\n",
    "X_train_numerical = X_train.loc[:, ['is_retweet', 'is_quoted', 'retweets', 'favorites', 'followers', 'verified',\n",
    "               'exclamation_mark_count', 'question_mark_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform 5-fold cross validation on each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the models and obtain test error estimates\n",
    "nb = naive_bayes(X_train[\"clean text\"].values, y_train.values)\n",
    "log = logistic(X_train[\"clean text\"].values, y_train.values)\n",
    "rf = random_forest(X_train[\"clean text\"].values, y_train.values)\n",
    "log_with_numeric = logistic(X_train[\"clean text\"].values, y_train.values, X_train_numerical.values)\n",
    "rf_with_numeric = random_forest(X_train[\"clean text\"].values, y_train.values, X_train_numerical.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.701417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.693044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.685683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression with Numerical</td>\n",
       "      <td>0.647866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest with Numerical</td>\n",
       "      <td>0.691342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy\n",
       "0                         Naive Bayes  0.701417\n",
       "1                 Logistic Regression  0.693044\n",
       "2                       Random Forest  0.685683\n",
       "3  Logistic Regression with Numerical  0.647866\n",
       "4        Random Forest with Numerical  0.691342"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_df = pd.DataFrame(data ={'Model':['Naive Bayes',\n",
    "                            'Logistic Regression',\n",
    "                            'Random Forest', \n",
    "                             'Logistic Regression with Numerical',\n",
    "                            'Random Forest with Numerical'], 'Accuracy': [nb,log,rf,log_with_numeric,rf_with_numeric] } )\n",
    "class3_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit the best model and obtain the final test error estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071487717361303"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "train = vectorizer.fit_transform(X_train[\"clean text\"].values)\n",
    "test = vectorizer.transform(X_test[\"clean text\"].values)\n",
    "        \n",
    "#naive bayes    \n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(train, y_train.values)\n",
    "      \n",
    "#obtain the test accuracy\n",
    "nb_classifier.score(test, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not much better than the null classifier as we found in the exploratory data analysis. To improve this we will next try:\n",
    "- upsampling\n",
    "- n-grams\n",
    "- scaling the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
